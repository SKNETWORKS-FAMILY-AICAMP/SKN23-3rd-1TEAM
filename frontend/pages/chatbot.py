import streamlit as st
import os
import time
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI
import io

# --- ê¸°ë³¸ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI ë©´ì ‘ê´€", page_icon="ğŸ¤–", layout="centered")

# --- CSS ìŠ¤íƒ€ì¼ ì ìš© (ì¹´ì¹´ì˜¤í†¡ ìŠ¤íƒ€ì¼) ---
st.markdown(
    """
<style>
/* ì „ì²´ ë°°ê²½ìƒ‰ */
.stApp {
    background-color: #b2c7d9;
}

/* ì±„íŒ… ì»¨í…Œì´ë„ˆ */
.chat-container {
    display: flex;
    flex-direction: column;
    gap: 10px;
    padding: 10px;
}

/* AI(ë©´ì ‘ê´€) ë§í’ì„  ìŠ¤íƒ€ì¼ */
.ai-message {
    align-self: flex-start;
    background-color: #ffffff;
    color: #000000;
    padding: 10px 15px;
    border-radius: 15px;
    border-top-left-radius: 0;
    max-width: 70%;
    box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    margin-bottom: 10px;
    position: relative;
    font-size: 15px;
}

/* ì‚¬ìš©ì ë§í’ì„  ìŠ¤íƒ€ì¼ */
.user-message {
    align-self: flex-end;
    background-color: #fef01b;
    color: #000000;
    padding: 10px 15px;
    border-radius: 15px;
    border-top-right-radius: 0;
    max-width: 70%;
    box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    margin-bottom: 10px;
    position: relative;
    font-size: 15px;
}

/* í™”ì ì´ë¦„ */
.sender-name {
    font-size: 12px;
    color: #4a4a4a;
    margin-bottom: 4px;
}

/* í—¤ë” ë° í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê°•ì œ ì§€ì • (ë‹¤í¬ëª¨ë“œ ë°©ì§€ìš©) */
h1, h2, h3, p, div {
    color: #333333;
}
</style>
""",
    unsafe_allow_html=True,
)

# --- ì¸ì¦ í™•ì¸ ---
if "user" not in st.session_state or st.session_state.user is None:
    st.warning("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì—°ë™ ---
# .env ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY", ""))
except Exception as e:
    client = None
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# --- Session State ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ì´ˆê¸° ì¸ì‚¬ë§
    st.session_state.messages.append(
        {
            "role": "assistant",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë©´ì ‘ì„ ì‹œì‘í•˜ê¸° ì „, ê°€ë³ê²Œ ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤. (ìŒì„±ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì‹œê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.)",
        }
    )

if "interview_ended" not in st.session_state:
    st.session_state.interview_ended = False

# --- UI ë ˆì´ì•„ì›ƒ ---
st.title("ğŸ¤– AI í™”ìƒ ë©´ì ‘")

# ìƒë‹¨: í† í‚¹í—¤ë“œ ìë¦¬ (Placeholder)
with st.container():
    st.markdown("### ğŸ¥ AI Interviewer Video")
    st.video(
        "https://www.w3schools.com/html/mov_bbb.mp4", format="video/mp4", start_time=0
    )
    st.caption(
        "â€» ì‹¤ì‹œê°„ AI í† í‚¹í—¤ë“œ ë° ë¦½ì‹±í¬(LivePortrait, MuseTalk) ëª¨ë¸ ì—°ë™ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤."
    )
st.divider()

# ì±„íŒ…ì°½ ì˜ì—­ ì‹œì‘ (CSS ì„¤ì •ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ)
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

# ì €ì¥ëœ ì±„íŒ… ë©”ì‹œì§€ ë Œë”ë§
for message in st.session_state.messages:
    if message["role"] == "user":
        st.markdown(
            f'<div style="display:flex; justify-content:flex-end;"><div class="user-message">{message["content"]}</div></div>',
            unsafe_allow_html=True,
        )
    elif message["role"] == "assistant":
        st.markdown(
            f'<div style="display:flex; justify-content:flex-start;"><div style="display:flex; flex-direction:column;"><div class="sender-name">ë©´ì ‘ê´€</div><div class="ai-message">{message["content"]}</div></div></div>',
            unsafe_allow_html=True,
        )

st.markdown("</div>", unsafe_allow_html=True)

# --- í•˜ë‹¨ ì…ë ¥ ì˜ì—­ (ë§ˆì´í¬ & í…ìŠ¤íŠ¸) ---
if not st.session_state.interview_ended:
    st.divider()

    # í…ìŠ¤íŠ¸ ì±„íŒ… ì…ë ¥
    prompt = st.chat_input("í…ìŠ¤íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # ìŒì„± ì…ë ¥ (Streamlit 1.36+ ê¸°ë³¸ ì œê³µ)
    with st.expander("ğŸ™ï¸ ë§ˆì´í¬ë¡œ ìŒì„± ë‹µë³€í•˜ê¸°", expanded=False):
        audio_val = st.audio_input(
            "ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ì”€í•˜ì‹  í›„ V(ì™„ë£Œ) ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        )

    # --- TTS ì¬ìƒ ì²˜ë¦¬ ---
    # ë°©ê¸ˆ ìƒì„±ëœ ë‹µë³€ì´ ìˆë‹¤ë©´ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤.
    if "latest_audio_content" in st.session_state:
        st.audio(
            st.session_state.latest_audio_content, format="audio/mp3", autoplay=True
        )
        # ì¬ìƒ í›„ì—ëŠ” ìƒíƒœì—ì„œ ì‚­ì œí•˜ì—¬ ë¦¬ë Œë”ë§ ì‹œ ë°˜ë³µ ì¬ìƒ ë°©ì§€
        del st.session_state.latest_audio_content

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë¡œì§ (STT ìš°ì„ , ì—†ìœ¼ë©´ Text)
    user_input_text = ""

    # 1. ì˜¤ë””ì˜¤ ì…ë ¥ ì²˜ë¦¬
    if audio_val is not None:
        audio_bytes = audio_val.getvalue()
        audio_hash = hash(audio_bytes)
        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
        if st.session_state.get("last_processed_audio") != audio_hash:
            st.session_state.last_processed_audio = audio_hash

            # --- STT ì²˜ë¦¬ ---
            with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    if client:
                        audio_file = io.BytesIO(audio_bytes)
                        audio_file.name = "audio.wav"
                        transcript = client.audio.transcriptions.create(
                            model="whisper-1", file=audio_file, language="ko"
                        )
                        user_input_text = transcript.text
                    else:
                        user_input_text = (
                            "[STT ë³€í™˜ ì„ì‹œ í…ìŠ¤íŠ¸: ì‚¬ìš©ìê°€ ìŒì„±ì„ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.]"
                        )
                except Exception as e:
                    st.error(f"STT ì—ëŸ¬ ë°œìƒ: {e}")
                    user_input_text = "[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]"

    # 2. í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ ì²˜ë¦¬
    elif prompt:
        user_input_text = prompt

    # ì…ë ¥ê°’ì´ ìˆì„ ê²½ìš° í™”ë©´ì— ì¶”ê°€ ë° AI ì‘ë‹µ ìš”ì²­
    if user_input_text:
        # User ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input_text})
        st.markdown(
            f'<div style="display:flex; justify-content:flex-end;"><div class="user-message">{user_input_text}</div></div>',
            unsafe_allow_html=True,
        )

        # AI(LLM) ì‘ë‹µ ìƒì„±
        with st.spinner("AI ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            system_prompt = {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ IT ë¶„ì•¼ì˜ ì „ë¬¸ì ì´ê³  ë‚ ì¹´ë¡œìš´ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë‹µë³€ì— ê¼¬ë¦¬ì§ˆë¬¸ì„ 1~2ê°œ ì •ë„ ë˜ì§‘ë‹ˆë‹¤. ë©´ì ‘ì´ ì¶©ë¶„íˆ ì§„í–‰ë˜ì—ˆë‹¤ê³  íŒë‹¨ë˜ë©´ (ëŒ€ëµ 3~4í„´ ì´ìƒ) ëŒ€í™” ë§ˆì§€ë§‰ì— [INTERVIEW_END] íƒœê·¸ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”.",
            }
            api_messages = [system_prompt] + st.session_state.messages

            try:
                if client:
                    response = client.chat.completions.create(
                        model="gpt-4o-mini", messages=api_messages, max_tokens=500
                    )
                    ai_reply = response.choices[0].message.content
                else:
                    ai_reply = (
                        "ì—°ê²°ëœ LLM ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. (.envì˜ OPENAI_API_KEY í™•ì¸ í•„ìš”)"
                    )
            except Exception as e:
                ai_reply = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

            # ë©´ì ‘ ì¢…ë£Œ íƒœê·¸ ê°ì§€
            if "[INTERVIEW_END]" in ai_reply:
                st.session_state.interview_ended = True
                ai_reply = ai_reply.replace("[INTERVIEW_END]", "").strip()

            st.session_state.messages.append({"role": "assistant", "content": ai_reply})
            st.markdown(
                f'<div style="display:flex; justify-content:flex-start;"><div style="display:flex; flex-direction:column;"><div class="sender-name">ë©´ì ‘ê´€</div><div class="ai-message">{ai_reply}</div></div></div>',
                unsafe_allow_html=True,
            )

            # --- TTS ì˜¤ë””ì˜¤ ìƒì„± ë° ì €ì¥ ---
            # ì—¬ê¸°ì„œ st.audioë¥¼ ë°”ë¡œ ë Œë”ë§í•˜ê³  st.rerun()ì„ í•´ë²„ë¦¬ë©´ ë Œë”ë§ëœ ìš”ì†Œê°€ ì¦‰ì‹œ ë‚ ì•„ê°€ë²„ë ¤ì„œ ì†Œë¦¬ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            # ë”°ë¼ì„œ session_stateì— ì €ì¥í•´ë‘ê³  ë‹¤ìŒ ë¦¬ë Œë”ë§ ì‚¬ì´í´ ìƒë‹¨ì—ì„œ ì¬ìƒí•˜ë„ë¡ í•©ë‹ˆë‹¤.
            if client:
                try:
                    tts_response = client.audio.speech.create(
                        model="tts-1",
                        voice="onyx",  # ë©´ì ‘ê´€ ëŠë‚Œì˜ ë‚®ì€ ëª©ì†Œë¦¬
                        input=ai_reply,
                    )
                    st.session_state.latest_audio_content = tts_response.content
                except Exception as e:
                    st.error(f"TTS ì¬ìƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            st.rerun()

    # ë©´ì ‘ ìˆ˜ë™ ì¢…ë£Œ ë²„íŠ¼
    if st.button("ë©´ì ‘ ìˆ˜ë™ ì¢…ë£Œ"):
        st.session_state.interview_ended = True
        st.rerun()

else:
    # --- ë©´ì ‘ ì¢…ë£Œ í›„ ê²°ê³¼ í™”ë©´ ---
    st.divider()
    st.success("ğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")

    st.subheader("ğŸ’¡ ë©´ì ‘ ê²°ê³¼ ë° í”¼ë“œë°±")

    with st.spinner("ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        # ì „ì²´ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±ì„ ìš”ì²­í•˜ëŠ” LLM í˜¸ì¶œ
        eval_prompt = "ë‹¤ìŒì€ ì‚¬ìš©ìì™€ AI ë©´ì ‘ê´€ì˜ ëŒ€í™” ë‚´ì—­ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ í”„ë ˆì  í…Œì´ì…˜/ë‹µë³€ ëŠ¥ë ¥ì— ëŒ€í•´ í•©ê²©/ë¶ˆí•©ê²© ì—¬ë¶€(ì„ì˜ íŒë‹¨ ê°€ëŠ¥), ì´ì (100ì  ë§Œì ), ê°•ì  2ê°€ì§€, ì•½ì  ë° ê°œì„ ì  2ê°€ì§€ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n\n"
        for m in st.session_state.messages[1:]:  # ì²« ì¸ì‚¬ë§ ì œì™¸
            role_str = "ë©´ì ‘ê´€" if m["role"] == "assistant" else "ì§€ì›ì"
            eval_prompt += f"{role_str}: {m['content']}\n"

        try:
            if client:
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": eval_prompt}],
                    max_tokens=1000,
                )
                evaluation = response.choices[0].message.content
            else:
                evaluation = "í‰ê°€ ê²°ê³¼ (ì„ì‹œ): ì˜ í•˜ì…¨ìŠµë‹ˆë‹¤. [API ì—°ë™ ì•ˆë¨]"
        except Exception as e:
            evaluation = "í‰ê°€ ìƒì„± ì¤‘ ì˜¤ë¥˜ í‘œì‹œ"

    st.markdown(evaluation)

    # í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸)
    script_text = ""
    for m in st.session_state.messages:
        role_str = "AI ë©´ì ‘ê´€" if m["role"] == "assistant" else "ë³¸ì¸"
        script_text += f"[{role_str}] {m['content']}\n"

    st.download_button(
        label="ğŸ“„ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ (.txt)",
        data=script_text.encode("utf-8"),
        file_name="interview_script.txt",
        mime="text/plain",
    )

    # ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°
    if st.button("ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
        st.session_state.messages = []
        st.session_state.interview_ended = False
        st.rerun()
