"""
File: chatbot.py
Author: ê¹€ë‹¤ë¹ˆ
Created: 2026-02-21
Description: AI ë©´ì ‘ê´€ ì±„íŒ… í˜ì´ì§€ (ì¹´ì¹´ì˜¤í†¡ ìŠ¤íƒ€ì¼ UI)
             - í…ìŠ¤íŠ¸ ë©´ì ‘ ëª¨ë“œ: OpenAI GPT ì§ì ‘ í˜¸ì¶œ (STT/TTS í¬í•¨)
             - ì‹¤ì‹œê°„ ìŒì„± ë©´ì ‘ ëª¨ë“œ: OpenAI Realtime API + WebRTC (streamlit-realtime-audio)

Modification History:
- 2026-02-21 (ê¹€ë‹¤ë¹ˆ): ì´ˆê¸° ìƒì„± â€” ì¹´ì¹´ì˜¤í†¡ ìŠ¤íƒ€ì¼ UI, OpenAI GPT ë©´ì ‘ ë¡œì§
- 2026-02-22 (ê¹€ë‹¤ë¹ˆ): STT(Whisper)/TTS(onyx) ìŒì„± ì…ì¶œë ¥ ì—°ë™, ë©´ì ‘ ì¢…ë£Œ ì‹œ GPT-4o í”¼ë“œë°±
- 2026-02-22 (ê¹€ë‹¤ë¹ˆ): ì‹¤ì‹œê°„ ìŒì„± ë©´ì ‘ ëª¨ë“œ ì¶”ê°€ (streamlit-realtime-audio + OpenAI Realtime API)
"""

import streamlit as st
import os
import sys
import time
import io

# ì™¸ë¶€ íŒ¨í‚¤ì§€ ê²½ë¡œ
_EXT_PKG_PATH = "/tmp/fw_pkg"
if os.path.isdir(_EXT_PKG_PATH) and _EXT_PKG_PATH not in sys.path:
    sys.path.insert(0, _EXT_PKG_PATH)

from openai import OpenAI

# streamlit-realtime-audio ì„í¬íŠ¸ (ì‹¤ì‹œê°„ ëª¨ë“œìš©)
try:
    from st_realtime_audio import realtime_audio_conversation

    _REALTIME_AVAILABLE = True
except ImportError:
    _REALTIME_AVAILABLE = False

# --- ê¸°ë³¸ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI ë©´ì ‘ê´€", page_icon="ğŸ¤–", layout="centered")

# --- CSS ìŠ¤íƒ€ì¼ ì ìš© (ì¹´ì¹´ì˜¤í†¡ ìŠ¤íƒ€ì¼) ---
st.markdown(
    """
<style>
.stApp { background-color: #b2c7d9; }

.ai-message {
    align-self: flex-start;
    background-color: #ffffff; color: #000000;
    padding: 10px 15px; border-radius: 15px; border-top-left-radius: 0;
    max-width: 70%; box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    margin-bottom: 10px; font-size: 15px; line-height: 1.5;
}
.user-message {
    align-self: flex-end;
    background-color: #fef01b; color: #000000;
    padding: 10px 15px; border-radius: 15px; border-top-right-radius: 0;
    max-width: 70%; box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    margin-bottom: 10px; font-size: 15px; line-height: 1.5;
}
.sender-name { font-size: 12px; color: #4a4a4a; margin-bottom: 4px; }

.realtime-status {
    display: inline-block; padding: 6px 16px; border-radius: 20px;
    font-weight: 600; font-size: 14px; margin-bottom: 16px;
}
.status-recording { background: #fee2e2; color: #dc2626; }
.status-connected { background: #dcfce7; color: #16a34a; }
.status-speaking { background: #dbeafe; color: #2563eb; }
.status-idle { background: #f3f4f6; color: #6b7280; }

h1, h2, h3, p, div { color: #333333; }
</style>
""",
    unsafe_allow_html=True,
)

# --- ì¸ì¦ í™•ì¸ ---
if "user" not in st.session_state or st.session_state.user is None:
    st.warning("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ---
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY", ""))
except Exception:
    client = None
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# --- Session State ì´ˆê¸°í™” ---
defaults = {
    "messages": [],
    "interview_ended": False,
    "last_processed_audio": None,
    "interview_mode": None,  # "text" or "realtime"
    "chatbot_started": False,
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ============================================================
# UI
# ============================================================
st.title("ğŸ¤– AI ë©´ì ‘ê´€")


# ============================================================
# ë©´ì ‘ ì‹œì‘ ì „: ëª¨ë“œ ì„ íƒ + ì„¤ì •
# ============================================================
if not st.session_state.chatbot_started:
    st.markdown("### âš™ï¸ ë©´ì ‘ ì„¤ì •")

    mode = st.radio(
        "ë©´ì ‘ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”",
        ["ğŸ’¬ í…ìŠ¤íŠ¸ ë©´ì ‘", "ğŸ™ï¸ ì‹¤ì‹œê°„ ìŒì„± ë©´ì ‘"],
        captions=[
            "íƒ€ì´í•‘ ë˜ëŠ” ìŒì„±ë…¹ìŒìœ¼ë¡œ ë‹µë³€. GPT-4o-mini ì‚¬ìš©.",
            (
                "ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”. ~300ms ì¦‰ì‹œ ì‘ë‹µ. ìë™ í„´í…Œì´í‚¹. (OpenAI Realtime API)"
                if _REALTIME_AVAILABLE
                else "âš ï¸ streamlit-realtime-audio ë¯¸ì„¤ì¹˜"
            ),
        ],
        index=0,
    )

    is_realtime = "ì‹¤ì‹œê°„" in mode
    if is_realtime and not _REALTIME_AVAILABLE:
        st.error(
            "streamlit-realtime-audioê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `pip install streamlit-realtime-audio`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        )
        st.stop()

    st.divider()

    job_role = st.selectbox(
        "ğŸ’¼ ì§ë¬´ ì„ íƒ",
        ["Python ë°±ì—”ë“œ ê°œë°œì", "Java ë°±ì—”ë“œ", "ë°ì´í„° ì—”ì§€ë‹ˆì–´", "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì"],
    )
    difficulty = st.select_slider(
        "ğŸ”¥ ë‚œì´ë„", options=["ì£¼ë‹ˆì–´", "ë¯¸ë“¤", "ì‹œë‹ˆì–´"], value="ë¯¸ë“¤"
    )
    q_count = st.slider("ğŸ”¢ ë¬¸í•­ ìˆ˜", 3, 10, 5)

    if st.button("â–¶ï¸ ë©´ì ‘ ì‹œì‘", type="primary", use_container_width=True):
        st.session_state.interview_mode = "realtime" if is_realtime else "text"
        st.session_state.chatbot_started = True
        st.session_state.job_role = job_role
        st.session_state.difficulty = difficulty
        st.session_state.q_count = q_count

        if not is_realtime:
            st.session_state.messages.append(
                {
                    "role": "assistant",
                    "content": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë©´ì ‘ì„ ì‹œì‘í•˜ê¸° ì „, ê°€ë³ê²Œ ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                }
            )
        st.rerun()

    st.stop()


# ============================================================
# ğŸ™ï¸ ì‹¤ì‹œê°„ ìŒì„± ë©´ì ‘ ëª¨ë“œ
# ============================================================
if st.session_state.interview_mode == "realtime":
    job_role = st.session_state.get("job_role", "Python ë°±ì—”ë“œ ê°œë°œì")
    difficulty = st.session_state.get("difficulty", "ë¯¸ë“¤")
    q_count = st.session_state.get("q_count", 5)

    st.markdown("### ğŸ™ï¸ ì‹¤ì‹œê°„ ìŒì„± ë©´ì ‘")
    st.info(
        "ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•˜ë©´ ë©´ì ‘ì´ ì‹œì‘ë©ë‹ˆë‹¤. ë§ì„ ë§ˆì¹˜ë©´ AIê°€ ì¦‰ì‹œ ì‘ë‹µí•©ë‹ˆë‹¤."
    )

    api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        st.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    instructions = f"""ë‹¹ì‹ ì€ {job_role} ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ê¸°ìˆ  ë©´ì ‘ì„ ì§„í–‰í•˜ì„¸ìš”.
ë‚œì´ë„: {difficulty}. ì´ {q_count}ê°œ ì§ˆë¬¸.

ê·œì¹™:
1. "ë°˜ê°‘ìŠµë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤."ë¡œ ì‹œì‘
2. ë‹µë³€ì— ëŒ€í•´ ê¸°ìˆ ì  ê¼¬ë¦¬ì§ˆë¬¸ 1~2ê°œ
3. ê° ë‹µë³€ì— ê°„ë‹¨í•œ í”¼ë“œë°± í›„ ë‹¤ìŒ ì§ˆë¬¸
4. {q_count}ê°œ ì§ˆë¬¸ ì™„ë£Œ í›„ ì¢…í•© í‰ê°€
5. ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ í†¤ ìœ ì§€"""

    result = realtime_audio_conversation(
        api_key=api_key,
        instructions=instructions,
        voice="onyx",
        temperature=0.7,
        turn_detection_threshold=0.5,
        auto_start=False,
        key="interview_realtime",
    )

    # ìƒíƒœ ì¸ë””ì¼€ì´í„°
    status = result.get("status", "idle")
    status_map = {
        "idle": ("ëŒ€ê¸° ì¤‘", "status-idle"),
        "connecting": ("ì—°ê²° ì¤‘...", "status-idle"),
        "connected": ("ì—°ê²°ë¨ â€” ë§ˆì´í¬ í™œì„±í™”", "status-connected"),
        "recording": ("ë“£ëŠ” ì¤‘...", "status-recording"),
        "speaking": ("ë©´ì ‘ê´€ì´ ë§í•˜ëŠ” ì¤‘...", "status-speaking"),
    }
    label, css_class = status_map.get(status, ("ì•Œ ìˆ˜ ì—†ìŒ", "status-idle"))
    st.markdown(
        f'<span class="realtime-status {css_class}">{label}</span>',
        unsafe_allow_html=True,
    )

    if result.get("error"):
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {result['error']}")

    # ì‹¤ì‹œê°„ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸
    transcript = result.get("transcript", [])
    if transcript:
        st.markdown("---")
        st.markdown("#### ğŸ“ ëŒ€í™” ê¸°ë¡")
        for msg in transcript:
            if msg.get("type") == "user":
                st.markdown(
                    f'<div style="display:flex; justify-content:flex-end;">'
                    f'<div class="user-message">{msg.get("content", "")}</div></div>',
                    unsafe_allow_html=True,
                )
            else:
                content = msg.get("content", "")
                if content:
                    st.markdown(
                        f'<div style="display:flex; justify-content:flex-start;">'
                        f'<div style="display:flex;flex-direction:column;">'
                        f'<div class="sender-name">ë©´ì ‘ê´€</div>'
                        f'<div class="ai-message">{content}</div>'
                        f"</div></div>",
                        unsafe_allow_html=True,
                    )

    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ›‘ ë©´ì ‘ ì¢…ë£Œ", use_container_width=True):
            st.session_state.interview_ended = True
            st.session_state.messages = [
                {"role": m.get("type", "user"), "content": m.get("content", "")}
                for m in transcript
                if m.get("content")
            ]
            st.rerun()
    with col2:
        if transcript:
            script = "\n".join(
                [
                    f"[{'AI ë©´ì ‘ê´€' if m.get('type')=='assistant' else 'ë³¸ì¸'}] {m.get('content','')}"
                    for m in transcript
                    if m.get("content")
                ]
            )
            st.download_button(
                "ğŸ“„ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ",
                script.encode("utf-8"),
                file_name="interview_realtime.txt",
                mime="text/plain",
                use_container_width=True,
            )

    if st.session_state.interview_ended:
        st.success("ğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
        if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
            for k in defaults:
                st.session_state[k] = defaults[k]
            st.rerun()
    st.stop()


# ============================================================
# ğŸ’¬ í…ìŠ¤íŠ¸ ë©´ì ‘ ëª¨ë“œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ============================================================

# ìƒë‹¨: í† í‚¹í—¤ë“œ ìë¦¬ (Placeholder)
with st.container():
    st.markdown("### ğŸ¥ AI Interviewer Video")
    st.video(
        "https://www.w3schools.com/html/mov_bbb.mp4", format="video/mp4", start_time=0
    )
    st.caption("â€» ì‹¤ì‹œê°„ AI í† í‚¹í—¤ë“œ ë° ë¦½ì‹±í¬ ëª¨ë¸ ì—°ë™ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
st.divider()

# ì±„íŒ… ë©”ì‹œì§€ ë Œë”ë§
st.markdown('<div class="chat-container">', unsafe_allow_html=True)
for message in st.session_state.messages:
    if message["role"] == "user":
        st.markdown(
            f'<div style="display:flex; justify-content:flex-end;"><div class="user-message">{message["content"]}</div></div>',
            unsafe_allow_html=True,
        )
    elif message["role"] == "assistant":
        st.markdown(
            f'<div style="display:flex; justify-content:flex-start;"><div style="display:flex; flex-direction:column;"><div class="sender-name">ë©´ì ‘ê´€</div><div class="ai-message">{message["content"]}</div></div></div>',
            unsafe_allow_html=True,
        )
st.markdown("</div>", unsafe_allow_html=True)

# TTS ì¬ìƒ
if "latest_audio_content" in st.session_state:
    st.audio(st.session_state.latest_audio_content, format="audio/mp3", autoplay=True)
    del st.session_state.latest_audio_content

# --- í•˜ë‹¨ ì…ë ¥ ì˜ì—­ ---
if not st.session_state.interview_ended:
    st.divider()

    prompt = st.chat_input("í…ìŠ¤íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    with st.expander("ğŸ™ï¸ ë§ˆì´í¬ë¡œ ìŒì„± ë‹µë³€í•˜ê¸°", expanded=False):
        audio_val = st.audio_input(
            "ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ì”€í•˜ì‹  í›„ V(ì™„ë£Œ) ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        )

    user_input_text = ""

    # 1. ì˜¤ë””ì˜¤ ì…ë ¥ â†’ STT
    if audio_val is not None:
        audio_bytes = audio_val.getvalue()
        audio_hash = hash(audio_bytes)
        if st.session_state.get("last_processed_audio") != audio_hash:
            st.session_state.last_processed_audio = audio_hash
            with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    if client:
                        audio_file = io.BytesIO(audio_bytes)
                        audio_file.name = "audio.wav"
                        transcript = client.audio.transcriptions.create(
                            model="whisper-1", file=audio_file, language="ko"
                        )
                        user_input_text = transcript.text
                    else:
                        user_input_text = "[STT ë³€í™˜ ì‹¤íŒ¨: API í‚¤ ì—†ìŒ]"
                except Exception as e:
                    st.error(f"STT ì—ëŸ¬: {e}")
                    user_input_text = "[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]"

    # 2. í…ìŠ¤íŠ¸ ì…ë ¥
    elif prompt:
        user_input_text = prompt

    # 3. LLM ì‘ë‹µ + TTS
    if user_input_text:
        st.session_state.messages.append({"role": "user", "content": user_input_text})

        with st.spinner("AI ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            job_role = st.session_state.get("job_role", "Python ë°±ì—”ë“œ ê°œë°œì")
            difficulty = st.session_state.get("difficulty", "ë¯¸ë“¤")
            q_count = st.session_state.get("q_count", 5)

            system_prompt = {
                "role": "system",
                "content": f"ë‹¹ì‹ ì€ {job_role} ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë‚œì´ë„: {difficulty}. "
                f"ì‚¬ìš©ìì˜ ë‹µë³€ì— ê¼¬ë¦¬ì§ˆë¬¸ì„ 1~2ê°œ ë˜ì§‘ë‹ˆë‹¤. "
                f"ë©´ì ‘ì´ ì¶©ë¶„íˆ ì§„í–‰ë˜ë©´ (ëŒ€ëµ {q_count}í„´ ì´ìƒ) ë§ˆì§€ë§‰ì— [INTERVIEW_END] íƒœê·¸ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”.",
            }
            api_messages = [system_prompt] + st.session_state.messages

            try:
                if client:
                    response = client.chat.completions.create(
                        model="gpt-4o-mini", messages=api_messages, max_tokens=500
                    )
                    ai_reply = response.choices[0].message.content
                else:
                    ai_reply = "LLM ì—°ê²° ì‹¤íŒ¨ (.envì˜ OPENAI_API_KEY í™•ì¸)"
            except Exception as e:
                ai_reply = f"ì‘ë‹µ ì˜¤ë¥˜: {e}"

            if "[INTERVIEW_END]" in ai_reply:
                st.session_state.interview_ended = True
                ai_reply = ai_reply.replace("[INTERVIEW_END]", "").strip()

            st.session_state.messages.append({"role": "assistant", "content": ai_reply})

            # TTS
            if client:
                try:
                    tts_response = client.audio.speech.create(
                        model="tts-1", voice="onyx", input=ai_reply
                    )
                    st.session_state.latest_audio_content = tts_response.content
                except Exception as e:
                    st.error(f"TTS ì˜¤ë¥˜: {e}")

            st.rerun()

    if st.button("ğŸ›‘ ë©´ì ‘ ìˆ˜ë™ ì¢…ë£Œ"):
        st.session_state.interview_ended = True
        st.rerun()

else:
    # --- ë©´ì ‘ ì¢…ë£Œ í›„ ê²°ê³¼ ---
    st.divider()
    st.success("ğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")
    st.subheader("ğŸ’¡ ë©´ì ‘ ê²°ê³¼ ë° í”¼ë“œë°±")

    with st.spinner("ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        eval_prompt = "ë‹¤ìŒì€ ì‚¬ìš©ìì™€ AI ë©´ì ‘ê´€ì˜ ëŒ€í™” ë‚´ì—­ì…ë‹ˆë‹¤. í•©ê²©/ë¶ˆí•©ê²©, ì´ì (100ì ), ê°•ì  2ê°€ì§€, ì•½ì  2ê°€ì§€ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n\n"
        for m in st.session_state.messages[1:]:
            role_str = "ë©´ì ‘ê´€" if m["role"] == "assistant" else "ì§€ì›ì"
            eval_prompt += f"{role_str}: {m['content']}\n"

        try:
            if client:
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": eval_prompt}],
                    max_tokens=1000,
                )
                evaluation = response.choices[0].message.content
            else:
                evaluation = "í‰ê°€ ê²°ê³¼ (ì„ì‹œ): [API ì—°ë™ ì•ˆë¨]"
        except Exception as e:
            evaluation = f"í‰ê°€ ì˜¤ë¥˜: {e}"

    st.markdown(evaluation)

    script_text = "\n".join(
        [
            f"[{'AI ë©´ì ‘ê´€' if m['role']=='assistant' else 'ë³¸ì¸'}] {m['content']}"
            for m in st.session_state.messages
        ]
    )
    st.download_button(
        "ğŸ“„ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ",
        script_text.encode("utf-8"),
        file_name="interview_script.txt",
        mime="text/plain",
    )

    if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
        for k in defaults:
            st.session_state[k] = defaults[k]
        st.rerun()
